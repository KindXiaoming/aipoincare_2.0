{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "import argparse\n",
    "\n",
    "\n",
    "\n",
    "def initialize():\n",
    "    session = {}\n",
    "    session['prepca'] = \"no\"\n",
    "    session['noise_threshold'] = \"0.001\"\n",
    "    session['hidden_widths'] = \"[256,256]\"\n",
    "    session['slope'] = \"0.0\"\n",
    "    session['L'] = \"[0.01,0.02,0.05,0.1,0.2,0.5,1.0]\"\n",
    "    session['opt'] = \"Adam\"\n",
    "    session['learning_rate'] = \"0.001\"\n",
    "    session['batch_size'] = \"128\"\n",
    "    session['training_iteration'] = \"2000\"\n",
    "    session['a'] = \"2\"\n",
    "    session['n_walk'] = \"4000\" \n",
    "    return session\n",
    "\n",
    "\n",
    "def train(session, model):\n",
    "    \n",
    "    #<--------------Pass Parameters-------------->\n",
    "    prepcaremove = session['prepca']\n",
    "    noise_threshold = float(session['noise_threshold'])\n",
    "    nn_widths = list(eval(session['hidden_widths']))\n",
    "    hidden_depth = len(nn_widths)\n",
    "    slope = float(session['slope'])\n",
    "    sigmals = eval(session['L'])\n",
    "    opt = session['opt']\n",
    "    lr = float(session['learning_rate'])\n",
    "    batch_size = int(session['batch_size'])\n",
    "    epoch = int(session['training_iteration'])\n",
    "    a = float(session['a'])\n",
    "    n_walk = int(session['n_walk'])\n",
    "    log = 200\n",
    "    \n",
    "    #<--------------Load data-------------->\n",
    "    xs = np.loadtxt(\"./saved_checkpoints/{}/Hmat/Hmat.txt\".format(model))\n",
    "    n_train = xs.shape[0]\n",
    "    input_dim = xs.shape[1]\n",
    "    \n",
    "    #<--------------Preprocessing-------------->\n",
    "    # normalize each H\n",
    "    xs = (xs - np.mean(xs, axis=0)[np.newaxis,:])/np.std(xs, axis=0)[np.newaxis,:]\n",
    "    \n",
    "    remove_dim = 0\n",
    "    if prepcaremove == \"yes\":\n",
    "        xs = xs/(np.std(xs,axis=0)[np.newaxis,:])\n",
    "    else:\n",
    "        pca = PCA()\n",
    "        xs = pca.fit_transform(xs)\n",
    "        input_dim_orig = input_dim\n",
    "        input_dim = np.sum(pca.explained_variance_ratio_>noise_threshold)\n",
    "        remove_dim = input_dim_orig - input_dim\n",
    "        xs = xs[:,:input_dim]\n",
    "        xs = xs/(np.std(xs,axis=0)[np.newaxis,:])\n",
    "\n",
    "    nn_widths.insert(0, input_dim)\n",
    "    nn_widths.append(input_dim)\n",
    "        \n",
    "    #<--------------Build Networks-------------->\n",
    "    class den(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(den, self).__init__()\n",
    "            self.linears = nn.ModuleList([nn.Linear(nn_widths[i], nn_widths[i+1]) for i in range(hidden_depth+1)])\n",
    "\n",
    "        def forward(self, x):\n",
    "            act = nn.LeakyReLU(slope)\n",
    "            self.x = x\n",
    "            for i in range(hidden_depth):\n",
    "                self.x = act(self.linears[i](self.x))\n",
    "            self.x = self.linears[hidden_depth](self.x)\n",
    "            return self.x\n",
    "    \n",
    "    #<--------------Training------------->\n",
    "    exps = []\n",
    "    losses = []\n",
    "\n",
    "    for sigmal in sigmals:\n",
    "        den_net = den()\n",
    "        criterion = nn.MSELoss()\n",
    "        if opt == \"Adam\":\n",
    "            optimizer = optim.Adam(den_net.parameters(), lr = lr)\n",
    "        else:\n",
    "            optimizer = optim.SGD(den_net.parameters(), lr = lr)\n",
    "        print(\"sigmal={}\".format(sigmal))\n",
    "\n",
    "        for j in range(epoch):\n",
    "            den_net.train()\n",
    "            optimizer.zero_grad()\n",
    "            choices = np.random.choice(n_train, batch_size)\n",
    "            perturb = torch.normal(0,sigmal,size=(batch_size,input_dim))\n",
    "            inputs0 = torch.tensor(xs[choices], dtype=torch.float) + perturb\n",
    "            outputs = den_net(inputs0)\n",
    "            loss = criterion(outputs, -perturb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(float(loss.data))\n",
    "\n",
    "            if j%log == 0:\n",
    "                print('Epoch:  %d | Train: %.3g' %(j, loss))\n",
    "\n",
    "        x0 = copy.deepcopy(xs[int(n_train/2)])\n",
    "        x0 = x0[np.newaxis,:]\n",
    "\n",
    "        x0 = x0 + np.random.randn(n_walk,input_dim) * sigmal\n",
    "        x0 = x0 + den_net(torch.tensor(x0,dtype=torch.float)).detach().numpy()\n",
    "\n",
    "        pca = PCA()\n",
    "        pca.fit(x0)\n",
    "        svs = pca.singular_values_\n",
    "        exp_ratio = svs**2/np.sum(svs**2)\n",
    "        exps.append(exp_ratio)\n",
    "\n",
    "        torch.save(den_net.state_dict(), \"./saved_checkpoints/{}/NEB/NEB_\".format(model)+\"%.3f\"%sigmal)\n",
    "\n",
    "    exps = np.array(exps)\n",
    "    \n",
    "    #<--------------Plotting------------->\n",
    "    # ERD\n",
    "    def f(x,a=2):\n",
    "        n = x.shape[1]\n",
    "        mask = x < 1/(a*n)\n",
    "        return n - np.sum(np.cos(np.pi/2*n*a*x)*mask,axis=1)\n",
    "    \n",
    "    ax1 = plt.figure(figsize=(7,5))\n",
    "    exps = np.array(exps)\n",
    "    for i in range(input_dim):\n",
    "        plt.plot(sigmals, exps[:,i], marker=\"o\", color=\"black\", ls=\"--\")\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel(r\"$L$\",fontsize=25)\n",
    "    plt.ylabel(\"Explained Ratio\",fontsize=25)\n",
    "\n",
    "    ax2 = ax1.gca().twinx()\n",
    "    neffs = f(exps, a=2)\n",
    "    ax2.plot(sigmals, neffs, marker=\"o\",color=\"red\",linewidth=5, markersize=15)\n",
    "    plt.ylabel(r\"$n_{eff}$\",fontsize=25,color=\"red\")\n",
    "\n",
    "    plt.savefig('./saved_checkpoints/{}/NEB/ERD.png'.format(model),bbox_inches=\"tight\")\n",
    "    np.savetxt('./saved_checkpoints/{}/NEB/sigmals.txt'.format(model), sigmals)\n",
    "    np.savetxt('./saved_checkpoints/{}/NEB/exp_ratio.txt'.format(model), exps)\n",
    "    np.savetxt('./saved_checkpoints/{}/NEB/Neff_L.txt'.format(model), neffs)\n",
    "    plt.clf()\n",
    "    # Neff histogram\n",
    "    den_nets = []\n",
    "    for j in range(len(sigmals)):\n",
    "        sigmal = sigmals[j]\n",
    "        den_net = den()\n",
    "        den_net.load_state_dict(torch.load(\"./saved_checkpoints/{}/NEB/NEB_\".format(model)+\"%.3f\"%sigmal))\n",
    "        den_nets.append(copy.deepcopy(den_net))\n",
    "        \n",
    "    exp_ratioss = []\n",
    "    npoint = 100\n",
    "\n",
    "    for i in range(npoint):\n",
    "        if i % 20 == 0:\n",
    "            print(i)\n",
    "        iid = np.random.choice(n_train)\n",
    "        x0 = copy.deepcopy(xs[iid])\n",
    "        x0 = x0[np.newaxis,:]\n",
    "\n",
    "        exp_ratios = []\n",
    "\n",
    "        for j in range(len(sigmals)):\n",
    "\n",
    "            x0 = x0 + np.random.randn(n_walk,input_dim) * sigmals[j]\n",
    "            x0 = x0 + den_nets[j](torch.tensor(x0,dtype=torch.float)).detach().numpy()\n",
    "\n",
    "            pca = PCA()\n",
    "            pca.fit(x0)\n",
    "            svs = pca.singular_values_\n",
    "            exp_ratio = svs**2/np.sum(svs**2)\n",
    "            exp_ratios.append(exp_ratio)\n",
    "        exp_ratioss.append(exp_ratios)\n",
    "    exp_ratioss = np.array(exp_ratioss)\n",
    "    \n",
    "    a = np.max(f(exp_ratioss.reshape(-1,input_dim)).reshape(npoint, len(sigmals)),axis=1)\n",
    "    a = np.round(a).astype('int')\n",
    "    counts = np.bincount(a)\n",
    "    neff = np.argmax(counts)\n",
    "    confidence = float(np.max(counts))/100.\n",
    "    plt.hist(a,bins=25)\n",
    "    plt.xlabel(r\"$n_{eff}$\",fontsize=20)\n",
    "    plt.ylabel(\"Count\",fontsize=20)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.savefig('./saved_checkpoints/{}/NEB/Neff_dist.png'.format(model),bbox_inches=\"tight\")\n",
    "    np.savetxt('./saved_checkpoints/{}/NEB/Neff_dist.txt'.format(model), a)\n",
    "    plt.clf()\n",
    "\n",
    "    return neff, confidence\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-model', type=str, required=True, help=\"model\")\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    session = initialize()\n",
    "    train(session, args.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
